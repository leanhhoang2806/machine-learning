
# Single Model training
sudo docker stop worker-0 | true && sudo docker rm worker-0 | true && sudo docker rmi --force my_tensorflow_app && sudo docker build -t my_tensorflow_app . && sudo docker run --gpus all --name worker-0  my_tensorflow_app

### Create and test images
# On Master or Single Model training
sudo docker stop worker-0 | true && sudo docker rm worker-0 | true && sudo docker rmi --force my_tensorflow_app && sudo docker build -t my_tensorflow_app . && sudo docker run --gpus all -p 2222:2222 -e TF_CONFIG='{"cluster": {"worker": ["192.168.1.100:2222", "192.168.1.101:2222"]}, "task": {"type": "worker", "index": 0}}' --name worker-0  my_tensorflow_app
# On worker
sudo docker stop worker-1 | true && sudo docker rm worker-1 | true && sudo docker rmi --force my_tensorflow_app && sudo docker build -t my_tensorflow_app . && sudo docker run --gpus all -p 2222:2222 -e TF_CONFIG='{"cluster": {"worker": ["192.168.1.100:2222", "192.168.1.101:2222"]}, "task": {"type": "worker", "index": 1}}' --name worker-1  my_tensorflow_app

### docker clean up, after removing all containers
sudo docker system prune -a --volumes

## Docker server
sudo systemctl start docker-desktop
sudo systemctl restart docker



#### Monitoring
nvtop 
htop

### Seting up home server
nmap -p 22 --open 192.168.1.0/24
ssh hoang2@192.168.1.101
ssh hoang@192.168.1.100
sudo pt-get install -y openssh-client

### set up ssh on all machine
947  ssh-keygen -t rsa
949  ssh-copy-id -i ~/.ssh/master_node_id_rsa.pub hoang2@192.168.1.101 # make sure both computher has their own copy of each other
950  ssh 'hoang2@192.168.1.101'



# On master machine
709  sudo swapoff -a
  710  sudo nano /etc/fstab
  711  sudp apt install docker.io -y
  712  sudo apt install docker.io -y
  713  sudo apt-get remove containerd.io
  714  sudo apt install docker.io -y
  715  curl -fsSL https://dl.k8s.io/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg
  716  echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
  717  sudo apt-get update
  718  sudo apt-get install -y kubelet kubeadm kubectl
  719  sudo apt-get install -y kubelet kubeadm kubectl kubernetes-cni -y
  720  sudo kubeadm init
  721  mkdir -p $HOME/.kube
  722  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  723  sudo chown $(id -u):$(id -g) $HOME/.kube/config
  724  kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
  725  kubectl get nodes
# debugtool
kubectl get pods --all-namespaces

if service keep crashing do this
https://github.com/kubernetes/kubernetes/issues/110177#issuecomment-1161647736

# set up cgroup
738  sudo docker info | grep Cgroup
 Cgroup Driver: systemd
 Cgroup Version: 2
sudo nano /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
=> add a flag `--cgroup-driver=systemd` to this line
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd"


# On slave machine install everything till 719 then install the `sudo kubeadm join` command from master

# Reset on both machine
sudo kubeadm reset

# apply deployment
/Documents/work/Machine_Learning/machine_learning$ kubectl create -f  model_selection.yaml 
kubectl exec -it model-selection-57d7f6748f-rgb6h -- /bin/bash

# install nvidia drivers
sudo apt install nvidia-driver-525 nvidia-dkms-525
reboot
#check install
nvidia-smi

# Instructions on installing docker container GPU runtime from nvidia
  128  distribution=$(. /etc/os-release;echo $ID$VERSION_ID)       && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg       && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list |             sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' |             sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
  129  distribution=$(. /etc/os-release;echo $ID$VERSION_ID)       && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg       && curl -s -L https://nvidia.github.io/libnvidia-container/experimental/$distribution/libnvidia-container.list |          sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' |          sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
  130  sudo apt-get update
  131  sudo apt-get install -y nvidia-container-toolkit
  132  sudo nvidia-ctk runtime configure --runtime=docker
  133  sudo systemctl restart docker


### Distributed training ====================
scp -r hoang@192.168.1.100:/home/hoang/Documents/work/Machine_Learning/machine_learning hoang2@192.168.1.101:/home/hoang2/Documents/work/Machine_Learning/machine_learning

# on master:
sudo docker stop worker-0 | true && sudo docker rm worker-1 | true && sudo docker rmi --force distributed-training-image && sudo docker build -t distributed-training-image . && sudo docker run -p 2222:2222 -e TF_CONFIG='{"cluster": {"worker": ["192.168.1.100:2222", "192.168.1.101:2222"]}, "task": {"type": "worker", "index": 0}}' --name worker-0 distributed-training-image

# on worker:
sudo docker stop worker-1 | true && sudo docker rm worker-2 | true && sudo docker rmi --force distributed-training-image && sudo docker build -t distributed-training-image . && sudo docker run -p 2222:2222 -e TF_CONFIG='{"cluster": {"worker": ["192.168.1.100:2222", "192.168.1.101:2222"]}, "task": {"type": "worker", "index": 1}}' --name worker-1 distributed-training-image
